{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9810f80-4183-4efc-9b00-76a8bd2683c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: Analyze music data to see how successful models are at predicting song danceability\n",
    "# Predictors: instrumentalness, tempo, temporal_features0-223\n",
    "# Data Source: https://github.com/mdeff/fma \n",
    "#    Subset of data with 13,133 songs\n",
    "#\n",
    "# Part 2: Training and Testing Models\n",
    "#    Multivariate Linear Regression\n",
    "#    RandomForest\n",
    "#    Multilayer Perceptron\n",
    "#    Boosting\n",
    "# Date last updated: 12/21/2023\n",
    "# Author: Kay Rubio\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import time\n",
    "# ignore future warnings that aren't necessary for this project\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a873eea9-8041-44e4-91a9-ffb96e2fe944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data built during data preparation (see separate notebook)\n",
    "x_train = pd.read_csv(\"./x_train.csv\")\n",
    "y_train = pd.read_csv(\"./y_train.csv\")\n",
    "x_test = pd.read_csv(\"./x_test.csv\")\n",
    "y_test = pd.read_csv(\"./y_test.csv\")\n",
    "# trimmed data for regression model only\n",
    "x_train_reg2 = pd.read_csv(\"./x_train_reg2.csv\")\n",
    "x_test_reg2 = pd.read_csv(\"./x_test_reg2.csv\")\n",
    "# further trimmed data for regression model only\n",
    "x_train_reg3 = pd.read_csv(\"./x_train_reg3.csv\")\n",
    "x_test_reg3 = pd.read_csv(\"./x_test_reg3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2a0b27b-d9b0-490e-bd19-0771f17fc919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temporal_features98</th>\n",
       "      <th>temporal_features99</th>\n",
       "      <th>temporal_features101</th>\n",
       "      <th>temporal_features110</th>\n",
       "      <th>temporal_features111</th>\n",
       "      <th>temporal_features113</th>\n",
       "      <th>temporal_features123</th>\n",
       "      <th>temporal_features125</th>\n",
       "      <th>temporal_features127</th>\n",
       "      <th>temporal_features129</th>\n",
       "      <th>...</th>\n",
       "      <th>temporal_features163</th>\n",
       "      <th>temporal_features165</th>\n",
       "      <th>temporal_features166</th>\n",
       "      <th>temporal_features183</th>\n",
       "      <th>temporal_features185</th>\n",
       "      <th>temporal_features200</th>\n",
       "      <th>temporal_features201</th>\n",
       "      <th>temporal_features214</th>\n",
       "      <th>temporal_features216</th>\n",
       "      <th>temporal_features217</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.366536</td>\n",
       "      <td>-7.917288</td>\n",
       "      <td>-29.483248</td>\n",
       "      <td>-10.969000</td>\n",
       "      <td>-12.683000</td>\n",
       "      <td>-31.177999</td>\n",
       "      <td>1745.207520</td>\n",
       "      <td>857.857544</td>\n",
       "      <td>450.171478</td>\n",
       "      <td>239.780121</td>\n",
       "      <td>...</td>\n",
       "      <td>159.458008</td>\n",
       "      <td>123.761002</td>\n",
       "      <td>125.893005</td>\n",
       "      <td>0.439256</td>\n",
       "      <td>3.663183</td>\n",
       "      <td>0.060203</td>\n",
       "      <td>0.043990</td>\n",
       "      <td>-0.284468</td>\n",
       "      <td>0.272164</td>\n",
       "      <td>0.200090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.757927</td>\n",
       "      <td>-6.526848</td>\n",
       "      <td>-2.927552</td>\n",
       "      <td>21.014500</td>\n",
       "      <td>-5.910500</td>\n",
       "      <td>-2.620500</td>\n",
       "      <td>481.618347</td>\n",
       "      <td>438.531799</td>\n",
       "      <td>173.483246</td>\n",
       "      <td>119.562477</td>\n",
       "      <td>...</td>\n",
       "      <td>187.322998</td>\n",
       "      <td>158.572998</td>\n",
       "      <td>143.895996</td>\n",
       "      <td>11.812191</td>\n",
       "      <td>2.641223</td>\n",
       "      <td>0.059045</td>\n",
       "      <td>0.046935</td>\n",
       "      <td>-2.943317</td>\n",
       "      <td>0.286168</td>\n",
       "      <td>0.219070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-24.476557</td>\n",
       "      <td>-14.597180</td>\n",
       "      <td>-30.570845</td>\n",
       "      <td>-19.882500</td>\n",
       "      <td>-14.056499</td>\n",
       "      <td>-32.332001</td>\n",
       "      <td>1041.254639</td>\n",
       "      <td>601.637512</td>\n",
       "      <td>616.665955</td>\n",
       "      <td>412.457336</td>\n",
       "      <td>...</td>\n",
       "      <td>237.859009</td>\n",
       "      <td>168.804993</td>\n",
       "      <td>160.173004</td>\n",
       "      <td>5.439683</td>\n",
       "      <td>2.165459</td>\n",
       "      <td>0.049192</td>\n",
       "      <td>0.032995</td>\n",
       "      <td>-2.471529</td>\n",
       "      <td>0.244255</td>\n",
       "      <td>0.220865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.759216</td>\n",
       "      <td>-10.643620</td>\n",
       "      <td>-25.965639</td>\n",
       "      <td>20.854000</td>\n",
       "      <td>-9.445499</td>\n",
       "      <td>-28.880001</td>\n",
       "      <td>316.353668</td>\n",
       "      <td>314.000122</td>\n",
       "      <td>99.852158</td>\n",
       "      <td>100.579712</td>\n",
       "      <td>...</td>\n",
       "      <td>111.977997</td>\n",
       "      <td>81.070999</td>\n",
       "      <td>61.323997</td>\n",
       "      <td>3.007475</td>\n",
       "      <td>3.836738</td>\n",
       "      <td>0.068552</td>\n",
       "      <td>0.035010</td>\n",
       "      <td>-2.516262</td>\n",
       "      <td>0.390579</td>\n",
       "      <td>0.275075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.503654</td>\n",
       "      <td>9.047318</td>\n",
       "      <td>-9.762955</td>\n",
       "      <td>56.953999</td>\n",
       "      <td>4.429500</td>\n",
       "      <td>-15.351999</td>\n",
       "      <td>2217.191895</td>\n",
       "      <td>1086.543945</td>\n",
       "      <td>420.112000</td>\n",
       "      <td>331.661926</td>\n",
       "      <td>...</td>\n",
       "      <td>190.218994</td>\n",
       "      <td>165.492004</td>\n",
       "      <td>184.391998</td>\n",
       "      <td>14.066206</td>\n",
       "      <td>12.843975</td>\n",
       "      <td>0.059838</td>\n",
       "      <td>0.045315</td>\n",
       "      <td>-2.203966</td>\n",
       "      <td>0.272245</td>\n",
       "      <td>0.208930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   temporal_features98  temporal_features99  temporal_features101  \\\n",
       "0            -5.366536            -7.917288            -29.483248   \n",
       "1            17.757927            -6.526848             -2.927552   \n",
       "2           -24.476557           -14.597180            -30.570845   \n",
       "3            17.759216           -10.643620            -25.965639   \n",
       "4            56.503654             9.047318             -9.762955   \n",
       "\n",
       "   temporal_features110  temporal_features111  temporal_features113  \\\n",
       "0            -10.969000            -12.683000            -31.177999   \n",
       "1             21.014500             -5.910500             -2.620500   \n",
       "2            -19.882500            -14.056499            -32.332001   \n",
       "3             20.854000             -9.445499            -28.880001   \n",
       "4             56.953999              4.429500            -15.351999   \n",
       "\n",
       "   temporal_features123  temporal_features125  temporal_features127  \\\n",
       "0           1745.207520            857.857544            450.171478   \n",
       "1            481.618347            438.531799            173.483246   \n",
       "2           1041.254639            601.637512            616.665955   \n",
       "3            316.353668            314.000122             99.852158   \n",
       "4           2217.191895           1086.543945            420.112000   \n",
       "\n",
       "   temporal_features129  ...  temporal_features163  temporal_features165  \\\n",
       "0            239.780121  ...            159.458008            123.761002   \n",
       "1            119.562477  ...            187.322998            158.572998   \n",
       "2            412.457336  ...            237.859009            168.804993   \n",
       "3            100.579712  ...            111.977997             81.070999   \n",
       "4            331.661926  ...            190.218994            165.492004   \n",
       "\n",
       "   temporal_features166  temporal_features183  temporal_features185  \\\n",
       "0            125.893005              0.439256              3.663183   \n",
       "1            143.895996             11.812191              2.641223   \n",
       "2            160.173004              5.439683              2.165459   \n",
       "3             61.323997              3.007475              3.836738   \n",
       "4            184.391998             14.066206             12.843975   \n",
       "\n",
       "   temporal_features200  temporal_features201  temporal_features214  \\\n",
       "0              0.060203              0.043990             -0.284468   \n",
       "1              0.059045              0.046935             -2.943317   \n",
       "2              0.049192              0.032995             -2.471529   \n",
       "3              0.068552              0.035010             -2.516262   \n",
       "4              0.059838              0.045315             -2.203966   \n",
       "\n",
       "   temporal_features216  temporal_features217  \n",
       "0              0.272164              0.200090  \n",
       "1              0.286168              0.219070  \n",
       "2              0.244255              0.220865  \n",
       "3              0.390579              0.275075  \n",
       "4              0.272245              0.208930  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the ID columns from the datasets\n",
    "x_train.drop('Unnamed: 0', axis=1, inplace=True) \n",
    "y_train.drop('Unnamed: 0', axis=1, inplace=True) \n",
    "x_test.drop('Unnamed: 0', axis=1, inplace=True) \n",
    "y_test.drop('Unnamed: 0', axis=1, inplace=True) \n",
    "x_train_reg2.drop('Unnamed: 0', axis=1, inplace=True) \n",
    "x_test_reg2.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "x_train_reg3.drop('Unnamed: 0', axis=1, inplace=True) \n",
    "x_test_reg3.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "x_test_reg2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "627641da-7881-4813-ba16-65d6ea62bcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model #1: Multivariate Linear Regression \n",
    "#\n",
    "# Version #1 using 27 temporal features, all with a correlation to danceability that is at least 0.3\n",
    "# but some predictors aren't normally distributed, have poor homoscedasticity with danceability, or lots of \n",
    "# multivariate outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c019954e-38e8-4350-9fdb-85784fdb664a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LinearRegression in module sklearn.linear_model._base:\n",
      "\n",
      "class LinearRegression(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, LinearModel)\n",
      " |  LinearRegression(*, fit_intercept=True, copy_X=True, n_jobs=None, positive=False)\n",
      " |  \n",
      " |  Ordinary least squares Linear Regression.\n",
      " |  \n",
      " |  LinearRegression fits a linear model with coefficients w = (w1, ..., wp)\n",
      " |  to minimize the residual sum of squares between the observed targets in\n",
      " |  the dataset, and the targets predicted by the linear approximation.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  fit_intercept : bool, default=True\n",
      " |      Whether to calculate the intercept for this model. If set\n",
      " |      to False, no intercept will be used in calculations\n",
      " |      (i.e. data is expected to be centered).\n",
      " |  \n",
      " |  copy_X : bool, default=True\n",
      " |      If True, X will be copied; else, it may be overwritten.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of jobs to use for the computation. This will only provide\n",
      " |      speedup in case of sufficiently large problems, that is if firstly\n",
      " |      `n_targets > 1` and secondly `X` is sparse or if `positive` is set\n",
      " |      to `True`. ``None`` means 1 unless in a\n",
      " |      :obj:`joblib.parallel_backend` context. ``-1`` means using all\n",
      " |      processors. See :term:`Glossary <n_jobs>` for more details.\n",
      " |  \n",
      " |  positive : bool, default=False\n",
      " |      When set to ``True``, forces the coefficients to be positive. This\n",
      " |      option is only supported for dense arrays.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : array of shape (n_features, ) or (n_targets, n_features)\n",
      " |      Estimated coefficients for the linear regression problem.\n",
      " |      If multiple targets are passed during the fit (y 2D), this\n",
      " |      is a 2D array of shape (n_targets, n_features), while if only\n",
      " |      one target is passed, this is a 1D array of length n_features.\n",
      " |  \n",
      " |  rank_ : int\n",
      " |      Rank of matrix `X`. Only available when `X` is dense.\n",
      " |  \n",
      " |  singular_ : array of shape (min(X, y),)\n",
      " |      Singular values of `X`. Only available when `X` is dense.\n",
      " |  \n",
      " |  intercept_ : float or array of shape (n_targets,)\n",
      " |      Independent term in the linear model. Set to 0.0 if\n",
      " |      `fit_intercept = False`.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  Ridge : Ridge regression addresses some of the\n",
      " |      problems of Ordinary Least Squares by imposing a penalty on the\n",
      " |      size of the coefficients with l2 regularization.\n",
      " |  Lasso : The Lasso is a linear model that estimates\n",
      " |      sparse coefficients with l1 regularization.\n",
      " |  ElasticNet : Elastic-Net is a linear regression\n",
      " |      model trained with both l1 and l2 -norm regularization of the\n",
      " |      coefficients.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  From the implementation point of view, this is just plain Ordinary\n",
      " |  Least Squares (scipy.linalg.lstsq) or Non Negative Least Squares\n",
      " |  (scipy.optimize.nnls) wrapped as a predictor object.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.linear_model import LinearRegression\n",
      " |  >>> X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
      " |  >>> # y = 1 * x_0 + 2 * x_1 + 3\n",
      " |  >>> y = np.dot(X, np.array([1, 2])) + 3\n",
      " |  >>> reg = LinearRegression().fit(X, y)\n",
      " |  >>> reg.score(X, y)\n",
      " |  1.0\n",
      " |  >>> reg.coef_\n",
      " |  array([1., 2.])\n",
      " |  >>> reg.intercept_\n",
      " |  3.0...\n",
      " |  >>> reg.predict(np.array([[3, 5]]))\n",
      " |  array([16.])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LinearRegression\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      LinearModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, fit_intercept=True, copy_X=True, n_jobs=None, positive=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training data.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_targets)\n",
      " |          Target values. Will be cast to X's dtype if necessary.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Individual weights for each sample.\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             parameter *sample_weight* support to LinearRegression.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted Estimator.\n",
      " |  \n",
      " |  set_fit_request(self: sklearn.linear_model._base.LinearRegression, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._base.LinearRegression\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_score_request(self: sklearn.linear_model._base.LinearRegression, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.linear_model._base.LinearRegression\n",
      " |      Request metadata passed to the ``score`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination of the prediction.\n",
      " |      \n",
      " |      The coefficient of determination :math:`R^2` is defined as\n",
      " |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      " |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      " |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always predicts\n",
      " |      the expected value of `y`, disregarding the input features, would get\n",
      " |      a :math:`R^2` score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from LinearModel:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape (n_samples,)\n",
      " |          Returns predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Learn some information about the model\n",
    "print(help(LinearRegression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec2fece8-b5bb-4270-aa00-ebf3eb5d432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model on the training data\n",
    "reg_model = LinearRegression().fit(x_train_reg2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b722a63-8018-42f4-8c60-497cf32ddc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55159423])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will give you an array holding the y-intercept of regression line\n",
    "reg_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3937a315-bf71-4d44-90eb-1ac85f90763c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.45284300e-03,  2.49173269e-03, -2.20370662e-05,\n",
       "        -5.68165904e-04,  8.15157717e-04,  2.85407819e-03,\n",
       "        -5.20622340e-06,  1.59983128e-05, -6.13149026e-05,\n",
       "         1.83624973e-04, -1.72962886e-06,  9.76786631e-05,\n",
       "        -4.70457901e-05, -3.02939623e-04,  1.49319875e-04,\n",
       "        -2.49358322e-04,  9.83725977e-05,  5.41487304e-05,\n",
       "        -4.60682061e-04,  2.50924929e-04, -5.76516729e-04,\n",
       "        -1.22380283e-03,  2.50310699e-01,  1.53355725e-01,\n",
       "        -4.01923455e-03, -4.27627123e-01,  2.15568282e-01]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the coefficients for each predictor, in the order that they appear in the training data\n",
    "reg_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86995737-be51-423b-9c8b-c0bd50a3a489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most of these regression coefficients are less than .05, indicating significant p-values, meaning most\n",
    "# predictors are significant in the model as a whole. Further refinement like step-wise regression could be done\n",
    "# to remove the few that aren't significant, but probably not necessary since I'll be running some more powerful models\n",
    "# down below like random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66367f63-6195-4fee-aa52-5ab76c3b1714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names: ['temporal_features98', 'temporal_features99', 'temporal_features101', 'temporal_features110', 'temporal_features111', 'temporal_features113', 'temporal_features123', 'temporal_features125', 'temporal_features127', 'temporal_features129', 'temporal_features130', 'temporal_features134', 'temporal_features139', 'temporal_features141', 'temporal_features149', 'temporal_features154', 'temporal_features161', 'temporal_features163', 'temporal_features165', 'temporal_features166', 'temporal_features183', 'temporal_features185', 'temporal_features200', 'temporal_features201', 'temporal_features214', 'temporal_features216', 'temporal_features217']\n"
     ]
    }
   ],
   "source": [
    "# If we were interested in seeing exactly which predictors were/weren't significant in the model, we could match the\n",
    "# array above with the column names to investigate further.\n",
    "column_names = x_train_reg2.columns.tolist()\n",
    "print(\"Column Names:\", column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "eeed2479-714b-4042-9ee3-3163e7251f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5993441649927478"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model.score(x_test_reg2, y_test) # Calculate R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a567f4c-7387-4c35-811a-39a5bfaf01c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared indicates that almost 60% of the variability in danceability can be explained by these temporal_features\n",
    "# which isn't bad for a linear model on kinda messy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1526d8c0-9367-4806-b3ba-a6b41a27f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg_model.predict(x_test_reg2) # get the predicted y-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "09a51179-612a-4cc6-839e-0350ce5590b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.43818462]\n",
      " [0.47774869]\n",
      " [0.47952883]\n",
      " ...\n",
      " [0.36269824]\n",
      " [0.43826685]\n",
      " [0.6187952 ]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "57300aed-18ff-41bb-ace8-ad44b145ef88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09947146084610314"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the mean absolute error (MAE) comparing the model's predicted outcomes with the actual outcomes\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a798df2-2945-4816-ae9c-b30f745baf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model's predictions are above/below the real outcome value by an avg of ~0.0995. Since danceability ranges from 0-1, that's not too bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec5152-4a7f-49b2-815b-163fe41783ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version #2 using 15 temporal features, all with a correlation to danceability that is at least 0.3\n",
    "# and all with somewhat better distributions and homoscedasticity with danceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "413de452-4b8d-4e25-a803-18ce04bc97b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.47234479e-03,  2.51936425e-03,  1.05799318e-03,\n",
       "        -8.39157778e-04,  1.37481307e-03,  3.03579692e-03,\n",
       "         1.06125685e-04, -3.39884753e-04, -6.31195384e-04,\n",
       "         3.70165265e-05, -3.23145539e-04,  9.83081232e-05,\n",
       "        -9.24754366e-05, -2.98982465e-04,  3.54915743e-04]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the the model on training data\n",
    "reg_model2 = LinearRegression().fit(x_train_reg3, y_train)\n",
    "# Check y-intercept and coefficients of each predictor\n",
    "reg_model2.intercept_\n",
    "reg_model2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "65b993c7-f9aa-4955-b0aa-21a3360ef650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5579600307506984"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model2.score(x_test_reg3, y_test) # Calculate R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeb7dfa-642c-4cc5-999b-abf485c4ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slightly worse R-squared from version #1, 56% of the variability in danceability can be explained by these temporal_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a7f704cb-d3e1-487e-84b9-0aa6626e12c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.41286885]\n",
      " [0.49285015]\n",
      " [0.4505156 ]\n",
      " ...\n",
      " [0.38253946]\n",
      " [0.43973822]\n",
      " [0.60906937]]\n"
     ]
    }
   ],
   "source": [
    "# get the predicted y-values\n",
    "y_pred = reg_model2.predict(x_test_reg3)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "68a793f3-5c25-433f-9364-40e446b44532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10578788198731864"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7915889-5ab5-4ac7-b75d-4fae479819b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 2 of multiple regression's predicted danceability scores are above/below the real values by an avg of ~0.11. \n",
    "# Since danceability ranges from 0-1, that's a little worse than the first regression model, as expected given the \n",
    "# slightly worse R-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e178bf3-3df8-4ed7-85e0-c9dd94a28cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model #2: RandomForestRegressor \n",
    "#    Version 1: Without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "09f0b4a9-e0ea-40ed-9c78-f9e6fa16ae18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomForestRegressor in module sklearn.ensemble._forest:\n",
      "\n",
      "class RandomForestRegressor(ForestRegressor)\n",
      " |  RandomForestRegressor(n_estimators=100, *, criterion='squared_error', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=1.0, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
      " |  \n",
      " |  A random forest regressor.\n",
      " |  \n",
      " |  A random forest is a meta estimator that fits a number of classifying\n",
      " |  decision trees on various sub-samples of the dataset and uses averaging\n",
      " |  to improve the predictive accuracy and control over-fitting.\n",
      " |  The sub-sample size is controlled with the `max_samples` parameter if\n",
      " |  `bootstrap=True` (default), otherwise the whole dataset is used to build\n",
      " |  each tree.\n",
      " |  \n",
      " |  For a comparison between tree-based ensemble models see the example\n",
      " |  :ref:`sphx_glr_auto_examples_ensemble_plot_forest_hist_grad_boosting_comparison.py`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <forest>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_estimators : int, default=100\n",
      " |      The number of trees in the forest.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``n_estimators`` changed from 10 to 100\n",
      " |         in 0.22.\n",
      " |  \n",
      " |  criterion : {\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"},             default=\"squared_error\"\n",
      " |      The function to measure the quality of a split. Supported criteria\n",
      " |      are \"squared_error\" for the mean squared error, which is equal to\n",
      " |      variance reduction as feature selection criterion and minimizes the L2\n",
      " |      loss using the mean of each terminal node, \"friedman_mse\", which uses\n",
      " |      mean squared error with Friedman's improvement score for potential\n",
      " |      splits, \"absolute_error\" for the mean absolute error, which minimizes\n",
      " |      the L1 loss using the median of each terminal node, and \"poisson\" which\n",
      " |      uses reduction in Poisson deviance to find splits.\n",
      " |      Training using \"absolute_error\" is significantly slower\n",
      " |      than when using \"squared_error\".\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Mean Absolute Error (MAE) criterion.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |         Poisson criterion.\n",
      " |  \n",
      " |  max_depth : int, default=None\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : {\"sqrt\", \"log2\", None}, int or float, default=1.0\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a fraction and\n",
      " |        `max(1, int(max_features * n_features_in_))` features are considered at each\n",
      " |        split.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None or 1.0, then `max_features=n_features`.\n",
      " |  \n",
      " |      .. note::\n",
      " |          The default of 1.0 is equivalent to bagged trees and more\n",
      " |          randomness can be achieved by setting smaller values, e.g. 0.3.\n",
      " |  \n",
      " |      .. versionchanged:: 1.1\n",
      " |          The default of `max_features` changed from `\"auto\"` to 1.0.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  bootstrap : bool, default=True\n",
      " |      Whether bootstrap samples are used when building trees. If False, the\n",
      " |      whole dataset is used to build each tree.\n",
      " |  \n",
      " |  oob_score : bool or callable, default=False\n",
      " |      Whether to use out-of-bag samples to estimate the generalization score.\n",
      " |      By default, :func:`~sklearn.metrics.r2_score` is used.\n",
      " |      Provide a callable with signature `metric(y_true, y_pred)` to use a\n",
      " |      custom metric. Only available if `bootstrap=True`.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
      " |      :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
      " |      trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors. See :term:`Glossary\n",
      " |      <n_jobs>` for more details.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls both the randomness of the bootstrapping of the samples used\n",
      " |      when building trees (if ``bootstrap=True``) and the sampling of the\n",
      " |      features to consider when looking for the best split at each node\n",
      " |      (if ``max_features < n_features``).\n",
      " |      See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Controls the verbosity when fitting and predicting.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just fit a whole\n",
      " |      new forest. See :term:`Glossary <warm_start>` and\n",
      " |      :ref:`gradient_boosting_warm_start` for details.\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  max_samples : int or float, default=None\n",
      " |      If bootstrap is True, the number of samples to draw from X\n",
      " |      to train each base estimator.\n",
      " |  \n",
      " |      - If None (default), then draw `X.shape[0]` samples.\n",
      " |      - If int, then draw `max_samples` samples.\n",
      " |      - If float, then draw `max(round(n_samples * max_samples), 1)` samples. Thus,\n",
      " |        `max_samples` should be in the interval `(0.0, 1.0]`.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  estimator_ : :class:`~sklearn.tree.DecisionTreeRegressor`\n",
      " |      The child estimator template used to create the collection of fitted\n",
      " |      sub-estimators.\n",
      " |  \n",
      " |      .. versionadded:: 1.2\n",
      " |         `base_estimator_` was renamed to `estimator_`.\n",
      " |  \n",
      " |  base_estimator_ : DecisionTreeRegressor\n",
      " |      The child estimator template used to create the collection of fitted\n",
      " |      sub-estimators.\n",
      " |  \n",
      " |      .. deprecated:: 1.2\n",
      " |          `base_estimator_` is deprecated and will be removed in 1.4.\n",
      " |          Use `estimator_` instead.\n",
      " |  \n",
      " |  estimators_ : list of DecisionTreeRegressor\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The impurity-based feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |  \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  oob_prediction_ : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |      Prediction computed with out-of-bag estimate on the training set.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  sklearn.tree.DecisionTreeRegressor : A decision tree regressor.\n",
      " |  sklearn.ensemble.ExtraTreesRegressor : Ensemble of extremely randomized\n",
      " |      tree regressors.\n",
      " |  sklearn.ensemble.HistGradientBoostingRegressor : A Histogram-based Gradient\n",
      " |      Boosting Regression Tree, very fast for big datasets (n_samples >=\n",
      " |      10_000).\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data,\n",
      " |  ``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      " |  of the criterion is identical for several splits enumerated during the\n",
      " |  search of the best split. To obtain a deterministic behaviour during\n",
      " |  fitting, ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  The default value ``max_features=1.0`` uses ``n_features``\n",
      " |  rather than ``n_features / 3``. The latter was originally suggested in\n",
      " |  [1], whereas the former was more recently justified empirically in [2].\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      " |  \n",
      " |  .. [2] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized\n",
      " |         trees\", Machine Learning, 63(1), 3-42, 2006.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.ensemble import RandomForestRegressor\n",
      " |  >>> from sklearn.datasets import make_regression\n",
      " |  >>> X, y = make_regression(n_features=4, n_informative=2,\n",
      " |  ...                        random_state=0, shuffle=False)\n",
      " |  >>> regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
      " |  >>> regr.fit(X, y)\n",
      " |  RandomForestRegressor(...)\n",
      " |  >>> print(regr.predict([[0, 0, 0, 0]]))\n",
      " |  [-8.32987858]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomForestRegressor\n",
      " |      ForestRegressor\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      BaseForest\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.ensemble._base.BaseEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_estimators=100, *, criterion='squared_error', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=1.0, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  set_fit_request(self: sklearn.ensemble._forest.RandomForestRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.ensemble._forest.RandomForestRegressor\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_score_request(self: sklearn.ensemble._forest.RandomForestRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.ensemble._forest.RandomForestRegressor\n",
      " |      Request metadata passed to the ``score`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ForestRegressor:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict regression target for X.\n",
      " |      \n",
      " |      The predicted regression target of an input sample is computed as the\n",
      " |      mean predicted regression targets of the trees in the forest.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination of the prediction.\n",
      " |      \n",
      " |      The coefficient of determination :math:`R^2` is defined as\n",
      " |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      " |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      " |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always predicts\n",
      " |      the expected value of `y`, disregarding the input features, would get\n",
      " |      a :math:`R^2` score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseForest:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the forest to X, return leaf indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : ndarray of shape (n_samples, n_estimators)\n",
      " |          For each datapoint x in X and for each tree in the forest,\n",
      " |          return the index of the leaf x ends up in.\n",
      " |  \n",
      " |  decision_path(self, X)\n",
      " |      Return the decision path in the forest.\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
      " |          Return a node indicator matrix where non zero elements indicates\n",
      " |          that the samples goes through the nodes. The matrix is of CSR\n",
      " |          format.\n",
      " |      \n",
      " |      n_nodes_ptr : ndarray of shape (n_estimators + 1,)\n",
      " |          The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]\n",
      " |          gives the indicator value for the i-th estimator.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a forest of trees from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, its dtype will be converted\n",
      " |          to ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseForest:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      The impurity-based feature importances.\n",
      " |      \n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |      \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          The values of this array sum to 1, unless all trees are single node\n",
      " |          trees consisting of only the root node, in which case it will be an\n",
      " |          array of zeros.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Return the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  base_estimator_\n",
      " |      Estimator used to grow the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# check information about the model and its hyperparameters\n",
    "print(help(RandomForestRegressor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d7809387-734e-4b0b-8b8a-993a6e3ed1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1aeb5920-f29d-4d56-8567-4aef7a22cb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using the training data Took ~3 min on my laptop\n",
    "rr.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "edec1fb5-a141-4c73-be01-c47ae4d8b791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation, which means split the dataset into pieces, and iterate over it \n",
    "# using a different piece as test and rest as train\n",
    "# This took about 15 minutes to run on my laptop\n",
    "scores = cross_val_score(rr, x_train, y_train.values.ravel(), cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "55a155f3-0b47-4c6a-90f6-884b909e09ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76016115, 0.73282828, 0.75136312, 0.7371274 , 0.74669975])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26098653-8119-4402-b484-4eb6f79e9052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is supposedly between 73-76% accurate when trained on 4/5 of the training data, and tested on the other 1/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fd0fc978-8466-4619-a5a1-a33c810f7fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48602867 0.43243468 0.47072673 ... 0.31505692 0.44021106 0.6864622 ]\n"
     ]
    }
   ],
   "source": [
    "# Get the predicted y-values\n",
    "y_pred = rr.predict(x_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "953ae616-d105-4564-8c60-3aad7f04eb46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07727108712718854"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Will give you MAE based on comparing the actual outcomes with predicted outcomes\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1935098f-5e68-4edf-881e-3970e8bd521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model's predicted danceability scores on test data are above/below the real danceability scores by an avg of ~0.0773. \n",
    "# Since danceability ranges from 0-1, that's pretty good, stronger than regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf3606-f831-47f1-9240-604de6baf32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 2: With hyperparameter tuning\n",
    "#    model above uses these default hyperparameters:\n",
    "#      n_estimators: (number of trees) default=100\n",
    "#      max_depth: (max depth of each tree) default=None\n",
    "\n",
    "# Model below will try these alternate hyperparameter settings\n",
    "#   n_estimators: [5, 50, 100]\n",
    "#   max_depth: [2, 10, 20, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1028823b-b542-4e78-826a-ee4e162f0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to help print results of each model\n",
    "def print_results(results):\n",
    "\tprint('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\tmeans = results.cv_results_['mean_test_score']\n",
    "\tstds = results.cv_results_['std_test_score']\n",
    "\tfor mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "\t\tprint('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e8c7bde9-ca00-4f28-b31e-2bbb71448db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a collection of parameters for hypertuning\n",
    "parameters = { \n",
    "    'n_estimators': [5, 50, 100],\n",
    "    'max_depth': [2, 10, 20, None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ab2b21ee-b93d-4b56-8eeb-57251c56b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "rr2 = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c5ece6b5-82ba-4427-a26b-62e913d034c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation which will split the dataset into 5 pieces, and iterate over it using a different piece as test and rest as train.\n",
    "# It will include the parameters to be hypertuned, and produce 3X4=12 models based on the hyperparameter combos\n",
    "cv = GridSearchCV(rr2, parameters, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f0aedd96-8327-469a-bd32-334bbfdd23dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 10, 20, None],\n",
       "                         &#x27;n_estimators&#x27;: [5, 50, 100]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 10, 20, None],\n",
       "                         &#x27;n_estimators&#x27;: [5, 50, 100]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={'max_depth': [2, 10, 20, None],\n",
       "                         'n_estimators': [5, 50, 100]})"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use cross-validation to fit the model\n",
    "# Took about 50 min to run on my laptop\n",
    "cv.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e2b961d0-7251-48c2-8f4f-807973e01b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'max_depth': None, 'n_estimators': 100}\n",
      "\n",
      "0.522 (+/-0.023) for {'max_depth': 2, 'n_estimators': 5}\n",
      "0.533 (+/-0.017) for {'max_depth': 2, 'n_estimators': 50}\n",
      "0.532 (+/-0.021) for {'max_depth': 2, 'n_estimators': 100}\n",
      "0.699 (+/-0.024) for {'max_depth': 10, 'n_estimators': 5}\n",
      "0.738 (+/-0.02) for {'max_depth': 10, 'n_estimators': 50}\n",
      "0.74 (+/-0.021) for {'max_depth': 10, 'n_estimators': 100}\n",
      "0.684 (+/-0.029) for {'max_depth': 20, 'n_estimators': 5}\n",
      "0.743 (+/-0.021) for {'max_depth': 20, 'n_estimators': 50}\n",
      "0.745 (+/-0.022) for {'max_depth': 20, 'n_estimators': 100}\n",
      "0.678 (+/-0.026) for {'max_depth': None, 'n_estimators': 5}\n",
      "0.743 (+/-0.02) for {'max_depth': None, 'n_estimators': 50}\n",
      "0.746 (+/-0.019) for {'max_depth': None, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a778ab3-81ac-449c-87e6-606a4583e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model uses {max_depth: None, n_estimators: 10} with accuracy of about 74.6%\n",
    "# Second best model uses {max_depth: 20, n_estimators: 100} with accuracy of about 74.5%\n",
    "# Third best model uses {max_depth: None, n_estimators: 50} with accuracy of about 74.4% and lower SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "43449208-5582-4376-a4c7-f66ca14465a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the 3 best sets of hyperparameters to create individual models\n",
    "rr1 = RandomForestRegressor(max_depth=None, n_estimators=100)\n",
    "rr2 = RandomForestRegressor(max_depth=20, n_estimators=100)\n",
    "rr3 = RandomForestRegressor(max_depth=None, n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e6c2593b-d92e-4915-9459-8d7117a880a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train models on training data\n",
    "rr1.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d58adc4b-abf5-4c25-bbf9-618ab0bcfdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=20)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=20)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr2.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a38910ca-6edf-4ae4-ab2c-05a73ac95bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=50)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr3.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a7f046f0-d189-4174-ad71-ddc35faef4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07734363446332014\n",
      "0.0772812648282704\n",
      "0.07771370618324094\n"
     ]
    }
   ],
   "source": [
    "# Check how good these models are on the training data. It's possible the best model was overfitting\n",
    "# and might not work as well on the training data\n",
    "for mdl in [rr1, rr2, rr3]:\n",
    "    y_pred = mdl.predict(x_test) # get the predicted y-values\n",
    "    print(mean_absolute_error(y_test, y_pred)) # print the mean difference between predicted and actual danceability score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65124274-a307-4e1a-84d0-a21e1c5d5aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, all 3 models are performing extremely simiarly, with their predicted danceability score only an avg of ~0.0773 pts away\n",
    "# from the real score. The second one performs slightly better on the test data than the others, so we'll assume this is the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0a3381b9-eec7-4316-a475-e20779427544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./RandomForestRegressor_model.pkl']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pickle best model\n",
    "joblib.dump(rr2, './RandomForestRegressor_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14fd525-80ba-4410-8401-e908b170d05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model #3: Multilayer Perceptron Regression Model\n",
    "#    Version 1: Without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9ccae319-07ac-4d8b-a7db-45c67c3b4dd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MLPRegressor in module sklearn.neural_network._multilayer_perceptron:\n",
      "\n",
      "class MLPRegressor(sklearn.base.RegressorMixin, BaseMultilayerPerceptron)\n",
      " |  MLPRegressor(hidden_layer_sizes=(100,), activation='relu', *, solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
      " |  \n",
      " |  Multi-layer Perceptron regressor.\n",
      " |  \n",
      " |  This model optimizes the squared error using LBFGS or stochastic gradient\n",
      " |  descent.\n",
      " |  \n",
      " |  .. versionadded:: 0.18\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  hidden_layer_sizes : array-like of shape(n_layers - 2,), default=(100,)\n",
      " |      The ith element represents the number of neurons in the ith\n",
      " |      hidden layer.\n",
      " |  \n",
      " |  activation : {'identity', 'logistic', 'tanh', 'relu'}, default='relu'\n",
      " |      Activation function for the hidden layer.\n",
      " |  \n",
      " |      - 'identity', no-op activation, useful to implement linear bottleneck,\n",
      " |        returns f(x) = x\n",
      " |  \n",
      " |      - 'logistic', the logistic sigmoid function,\n",
      " |        returns f(x) = 1 / (1 + exp(-x)).\n",
      " |  \n",
      " |      - 'tanh', the hyperbolic tan function,\n",
      " |        returns f(x) = tanh(x).\n",
      " |  \n",
      " |      - 'relu', the rectified linear unit function,\n",
      " |        returns f(x) = max(0, x)\n",
      " |  \n",
      " |  solver : {'lbfgs', 'sgd', 'adam'}, default='adam'\n",
      " |      The solver for weight optimization.\n",
      " |  \n",
      " |      - 'lbfgs' is an optimizer in the family of quasi-Newton methods.\n",
      " |  \n",
      " |      - 'sgd' refers to stochastic gradient descent.\n",
      " |  \n",
      " |      - 'adam' refers to a stochastic gradient-based optimizer proposed by\n",
      " |        Kingma, Diederik, and Jimmy Ba\n",
      " |  \n",
      " |      Note: The default solver 'adam' works pretty well on relatively\n",
      " |      large datasets (with thousands of training samples or more) in terms of\n",
      " |      both training time and validation score.\n",
      " |      For small datasets, however, 'lbfgs' can converge faster and perform\n",
      " |      better.\n",
      " |  \n",
      " |  alpha : float, default=0.0001\n",
      " |      Strength of the L2 regularization term. The L2 regularization term\n",
      " |      is divided by the sample size when added to the loss.\n",
      " |  \n",
      " |  batch_size : int, default='auto'\n",
      " |      Size of minibatches for stochastic optimizers.\n",
      " |      If the solver is 'lbfgs', the regressor will not use minibatch.\n",
      " |      When set to \"auto\", `batch_size=min(200, n_samples)`.\n",
      " |  \n",
      " |  learning_rate : {'constant', 'invscaling', 'adaptive'}, default='constant'\n",
      " |      Learning rate schedule for weight updates.\n",
      " |  \n",
      " |      - 'constant' is a constant learning rate given by\n",
      " |        'learning_rate_init'.\n",
      " |  \n",
      " |      - 'invscaling' gradually decreases the learning rate ``learning_rate_``\n",
      " |        at each time step 't' using an inverse scaling exponent of 'power_t'.\n",
      " |        effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
      " |  \n",
      " |      - 'adaptive' keeps the learning rate constant to\n",
      " |        'learning_rate_init' as long as training loss keeps decreasing.\n",
      " |        Each time two consecutive epochs fail to decrease training loss by at\n",
      " |        least tol, or fail to increase validation score by at least tol if\n",
      " |        'early_stopping' is on, the current learning rate is divided by 5.\n",
      " |  \n",
      " |      Only used when solver='sgd'.\n",
      " |  \n",
      " |  learning_rate_init : float, default=0.001\n",
      " |      The initial learning rate used. It controls the step-size\n",
      " |      in updating the weights. Only used when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  power_t : float, default=0.5\n",
      " |      The exponent for inverse scaling learning rate.\n",
      " |      It is used in updating effective learning rate when the learning_rate\n",
      " |      is set to 'invscaling'. Only used when solver='sgd'.\n",
      " |  \n",
      " |  max_iter : int, default=200\n",
      " |      Maximum number of iterations. The solver iterates until convergence\n",
      " |      (determined by 'tol') or this number of iterations. For stochastic\n",
      " |      solvers ('sgd', 'adam'), note that this determines the number of epochs\n",
      " |      (how many times each data point will be used), not the number of\n",
      " |      gradient steps.\n",
      " |  \n",
      " |  shuffle : bool, default=True\n",
      " |      Whether to shuffle samples in each iteration. Only used when\n",
      " |      solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      Determines random number generation for weights and bias\n",
      " |      initialization, train-test split if early stopping is used, and batch\n",
      " |      sampling when solver='sgd' or 'adam'.\n",
      " |      Pass an int for reproducible results across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      Tolerance for the optimization. When the loss or score is not improving\n",
      " |      by at least ``tol`` for ``n_iter_no_change`` consecutive iterations,\n",
      " |      unless ``learning_rate`` is set to 'adaptive', convergence is\n",
      " |      considered to be reached and training stops.\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Whether to print progress messages to stdout.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to True, reuse the solution of the previous\n",
      " |      call to fit as initialization, otherwise, just erase the\n",
      " |      previous solution. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  momentum : float, default=0.9\n",
      " |      Momentum for gradient descent update. Should be between 0 and 1. Only\n",
      " |      used when solver='sgd'.\n",
      " |  \n",
      " |  nesterovs_momentum : bool, default=True\n",
      " |      Whether to use Nesterov's momentum. Only used when solver='sgd' and\n",
      " |      momentum > 0.\n",
      " |  \n",
      " |  early_stopping : bool, default=False\n",
      " |      Whether to use early stopping to terminate training when validation\n",
      " |      score is not improving. If set to True, it will automatically set\n",
      " |      aside ``validation_fraction`` of training data as validation and\n",
      " |      terminate training when validation score is not improving by at\n",
      " |      least ``tol`` for ``n_iter_no_change`` consecutive epochs.\n",
      " |      Only effective when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  validation_fraction : float, default=0.1\n",
      " |      The proportion of training data to set aside as validation set for\n",
      " |      early stopping. Must be between 0 and 1.\n",
      " |      Only used if early_stopping is True.\n",
      " |  \n",
      " |  beta_1 : float, default=0.9\n",
      " |      Exponential decay rate for estimates of first moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'.\n",
      " |  \n",
      " |  beta_2 : float, default=0.999\n",
      " |      Exponential decay rate for estimates of second moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'.\n",
      " |  \n",
      " |  epsilon : float, default=1e-8\n",
      " |      Value for numerical stability in adam. Only used when solver='adam'.\n",
      " |  \n",
      " |  n_iter_no_change : int, default=10\n",
      " |      Maximum number of epochs to not meet ``tol`` improvement.\n",
      " |      Only effective when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  max_fun : int, default=15000\n",
      " |      Only used when solver='lbfgs'. Maximum number of function calls.\n",
      " |      The solver iterates until convergence (determined by ``tol``), number\n",
      " |      of iterations reaches max_iter, or this number of function calls.\n",
      " |      Note that number of function calls will be greater than or equal to\n",
      " |      the number of iterations for the MLPRegressor.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  loss_ : float\n",
      " |      The current loss computed with the loss function.\n",
      " |  \n",
      " |  best_loss_ : float\n",
      " |      The minimum loss reached by the solver throughout fitting.\n",
      " |      If `early_stopping=True`, this attribute is set to `None`. Refer to\n",
      " |      the `best_validation_score_` fitted attribute instead.\n",
      " |      Only accessible when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  loss_curve_ : list of shape (`n_iter_`,)\n",
      " |      Loss value evaluated at the end of each training step.\n",
      " |      The ith element in the list represents the loss at the ith iteration.\n",
      " |      Only accessible when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  validation_scores_ : list of shape (`n_iter_`,) or None\n",
      " |      The score at each iteration on a held-out validation set. The score\n",
      " |      reported is the R2 score. Only available if `early_stopping=True`,\n",
      " |      otherwise the attribute is set to `None`.\n",
      " |      Only accessible when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  best_validation_score_ : float or None\n",
      " |      The best validation score (i.e. R2 score) that triggered the\n",
      " |      early stopping. Only available if `early_stopping=True`, otherwise the\n",
      " |      attribute is set to `None`.\n",
      " |      Only accessible when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  t_ : int\n",
      " |      The number of training samples seen by the solver during fitting.\n",
      " |      Mathematically equals `n_iters * X.shape[0]`, it means\n",
      " |      `time_step` and it is used by optimizer's learning rate scheduler.\n",
      " |  \n",
      " |  coefs_ : list of shape (n_layers - 1,)\n",
      " |      The ith element in the list represents the weight matrix corresponding\n",
      " |      to layer i.\n",
      " |  \n",
      " |  intercepts_ : list of shape (n_layers - 1,)\n",
      " |      The ith element in the list represents the bias vector corresponding to\n",
      " |      layer i + 1.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      The number of iterations the solver has run.\n",
      " |  \n",
      " |  n_layers_ : int\n",
      " |      Number of layers.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      Number of outputs.\n",
      " |  \n",
      " |  out_activation_ : str\n",
      " |      Name of the output activation function.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  BernoulliRBM : Bernoulli Restricted Boltzmann Machine (RBM).\n",
      " |  MLPClassifier : Multi-layer Perceptron classifier.\n",
      " |  sklearn.linear_model.SGDRegressor : Linear model fitted by minimizing\n",
      " |      a regularized empirical loss with SGD.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  MLPRegressor trains iteratively since at each time step\n",
      " |  the partial derivatives of the loss function with respect to the model\n",
      " |  parameters are computed to update the parameters.\n",
      " |  \n",
      " |  It can also have a regularization term added to the loss function\n",
      " |  that shrinks model parameters to prevent overfitting.\n",
      " |  \n",
      " |  This implementation works with data represented as dense and sparse numpy\n",
      " |  arrays of floating point values.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  Hinton, Geoffrey E. \"Connectionist learning procedures.\"\n",
      " |  Artificial intelligence 40.1 (1989): 185-234.\n",
      " |  \n",
      " |  Glorot, Xavier, and Yoshua Bengio.\n",
      " |  \"Understanding the difficulty of training deep feedforward neural networks.\"\n",
      " |  International Conference on Artificial Intelligence and Statistics. 2010.\n",
      " |  \n",
      " |  :arxiv:`He, Kaiming, et al (2015). \"Delving deep into rectifiers:\n",
      " |  Surpassing human-level performance on imagenet classification.\" <1502.01852>`\n",
      " |  \n",
      " |  :arxiv:`Kingma, Diederik, and Jimmy Ba (2014)\n",
      " |  \"Adam: A method for stochastic optimization.\" <1412.6980>`\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.neural_network import MLPRegressor\n",
      " |  >>> from sklearn.datasets import make_regression\n",
      " |  >>> from sklearn.model_selection import train_test_split\n",
      " |  >>> X, y = make_regression(n_samples=200, random_state=1)\n",
      " |  >>> X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
      " |  ...                                                     random_state=1)\n",
      " |  >>> regr = MLPRegressor(random_state=1, max_iter=500).fit(X_train, y_train)\n",
      " |  >>> regr.predict(X_test[:2])\n",
      " |  array([-0.9..., -7.1...])\n",
      " |  >>> regr.score(X_test, y_test)\n",
      " |  0.4...\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MLPRegressor\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      BaseMultilayerPerceptron\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, hidden_layer_sizes=(100,), activation='relu', *, solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  partial_fit(self, X, y)\n",
      " |      Update the model with a single iteration over the given data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : ndarray of shape (n_samples,)\n",
      " |          The target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Trained MLP model.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the multi-layer perceptron model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples, n_outputs)\n",
      " |          The predicted values.\n",
      " |  \n",
      " |  set_score_request(self: sklearn.neural_network._multilayer_perceptron.MLPRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.neural_network._multilayer_perceptron.MLPRegressor\n",
      " |      Request metadata passed to the ``score`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination of the prediction.\n",
      " |      \n",
      " |      The coefficient of determination :math:`R^2` is defined as\n",
      " |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      " |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      " |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always predicts\n",
      " |      the expected value of `y`, disregarding the input features, would get\n",
      " |      a :math:`R^2` score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseMultilayerPerceptron:\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the model to data matrix X and target(s) y.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : ndarray or sparse matrix of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns a trained MLP model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from BaseMultilayerPerceptron:\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# print some information about the model and its hyperparameters\n",
    "print(help(MLPRegressor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e57aa861-a08a-482c-aaed-b1edefbc5de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model with some hyperparameters\n",
    "mlp = MLPRegressor(random_state=1, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "dec3cda1-fc89-4481-a38b-92332aee2c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(max_iter=500, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(max_iter=500, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(max_iter=500, random_state=1)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "# Did not take long on my laptop\n",
    "mlp.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "9a01e110-1b17-4921-ad72-943f383ce40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80079934 1.65063427 0.52247218 ... 0.49280228 1.44024457 0.90245539]\n"
     ]
    }
   ],
   "source": [
    "# Use the model to predict danceability scores in the test data\n",
    "y_pred = mlp.predict(x_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f975f6-6237-466a-8eaa-50c11bda3d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This isn't looking good, the outcome should not be above 1, and some of these are too high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "5861dfcd-4120-4569-b208-39c1b357913d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.322998348519081\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean difference between predicted and actual danceability in the test data\n",
    "mean_absolute_error(y_test, y_pred)\n",
    "print(mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede5b1d5-7175-43f4-8a66-d8e7c68b7628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg predicted score is 1.32 points away from the actual score. That's worse than regression and random forest\n",
    "# This may be expected because multilayer perceptron performs better when there's massive amounts of data and \n",
    "# there are only 10,000 songs in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "5b8f94c1-e5b9-4910-959c-0c0cd3fe4009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version #2: Multilayer Perceptron Regression Model with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "0a6f9dce-fdab-4945-9f4a-74a23c0ce4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_layer_sizes: an array of tuples, with first setting is number of nodes and second setting (left blank here for default) \n",
    "# is number of layers\n",
    "\n",
    "# activation: different activation functionality for the hidden layer\n",
    "\n",
    "parameters = {\n",
    "\t'hidden_layer_sizes': [(10,), (50,), (100,)],\n",
    "\t'activation': ['relu', 'tanh', 'logistic']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "dbe5f53e-8770-49ec-8a56-93aca2b8d19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model and set up grid serach cross validation with the hyperparameter settings\n",
    "mlp2 = MLPRegressor()\n",
    "cv = GridSearchCV(mlp2, parameters, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "2282860e-bdf9-400c-893c-756db45ab541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=MLPRegressor(),\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;relu&#x27;, &#x27;tanh&#x27;, &#x27;logistic&#x27;],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [(10,), (50,), (100,)]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=MLPRegressor(),\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;relu&#x27;, &#x27;tanh&#x27;, &#x27;logistic&#x27;],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [(10,), (50,), (100,)]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MLPRegressor(),\n",
       "             param_grid={'activation': ['relu', 'tanh', 'logistic'],\n",
       "                         'hidden_layer_sizes': [(10,), (50,), (100,)]})"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit all the models with various hyperparameter settings\n",
    "# Took only a few min to run on my laptop\n",
    "cv.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b967a6ef-c799-4c7c-84ff-b38028e6cd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'activation': 'logistic', 'hidden_layer_sizes': (50,)}\n",
      "\n",
      "-376.495 (+/-971.145) for {'activation': 'relu', 'hidden_layer_sizes': (10,)}\n",
      "-768.948 (+/-1640.969) for {'activation': 'relu', 'hidden_layer_sizes': (50,)}\n",
      "-698.479 (+/-407.968) for {'activation': 'relu', 'hidden_layer_sizes': (100,)}\n",
      "0.136 (+/-0.634) for {'activation': 'tanh', 'hidden_layer_sizes': (10,)}\n",
      "0.518 (+/-0.039) for {'activation': 'tanh', 'hidden_layer_sizes': (50,)}\n",
      "0.497 (+/-0.056) for {'activation': 'tanh', 'hidden_layer_sizes': (100,)}\n",
      "0.579 (+/-0.06) for {'activation': 'logistic', 'hidden_layer_sizes': (10,)}\n",
      "0.627 (+/-0.039) for {'activation': 'logistic', 'hidden_layer_sizes': (50,)}\n",
      "0.619 (+/-0.049) for {'activation': 'logistic', 'hidden_layer_sizes': (100,)}\n"
     ]
    }
   ],
   "source": [
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0f3bd6-05f4-4a11-8ad3-aadaa338cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation: relu has negative accuracy? \n",
    "# The rest have poorer accuracy than random forest, and at best reach only 63%\n",
    "# at best reaching 63% accuracy with these hyperparameters: {'activation': 'logistic', 'hidden_layer_sizes': (50,)}\n",
    "# This may be expected, as multilayer perceptron needs a ton of data, and the training data has less than 10,000 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a5220d-6c2d-430f-afdc-5c8ee79a155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model #4: Boosting Gradient Trees\n",
    "# Trees that learn from each other. Take longer to train than random forest, but fast to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "623955d6-28d5-4172-b605-e9c9af12524e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GradientBoostingRegressor in module sklearn.ensemble._gb:\n",
      "\n",
      "class GradientBoostingRegressor(sklearn.base.RegressorMixin, BaseGradientBoosting)\n",
      " |  GradientBoostingRegressor(*, loss='squared_error', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, init=None, random_state=None, max_features=None, alpha=0.9, verbose=0, max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
      " |  \n",
      " |  Gradient Boosting for regression.\n",
      " |  \n",
      " |  This estimator builds an additive model in a forward stage-wise fashion; it\n",
      " |  allows for the optimization of arbitrary differentiable loss functions. In\n",
      " |  each stage a regression tree is fit on the negative gradient of the given\n",
      " |  loss function.\n",
      " |  \n",
      " |  :class:`sklearn.ensemble.HistGradientBoostingRegressor` is a much faster\n",
      " |  variant of this algorithm for intermediate datasets (`n_samples >= 10_000`).\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <gradient_boosting>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  loss : {'squared_error', 'absolute_error', 'huber', 'quantile'},             default='squared_error'\n",
      " |      Loss function to be optimized. 'squared_error' refers to the squared\n",
      " |      error for regression. 'absolute_error' refers to the absolute error of\n",
      " |      regression and is a robust loss function. 'huber' is a\n",
      " |      combination of the two. 'quantile' allows quantile regression (use\n",
      " |      `alpha` to specify the quantile).\n",
      " |  \n",
      " |  learning_rate : float, default=0.1\n",
      " |      Learning rate shrinks the contribution of each tree by `learning_rate`.\n",
      " |      There is a trade-off between learning_rate and n_estimators.\n",
      " |      Values must be in the range `[0.0, inf)`.\n",
      " |  \n",
      " |  n_estimators : int, default=100\n",
      " |      The number of boosting stages to perform. Gradient boosting\n",
      " |      is fairly robust to over-fitting so a large number usually\n",
      " |      results in better performance.\n",
      " |      Values must be in the range `[1, inf)`.\n",
      " |  \n",
      " |  subsample : float, default=1.0\n",
      " |      The fraction of samples to be used for fitting the individual base\n",
      " |      learners. If smaller than 1.0 this results in Stochastic Gradient\n",
      " |      Boosting. `subsample` interacts with the parameter `n_estimators`.\n",
      " |      Choosing `subsample < 1.0` leads to a reduction of variance\n",
      " |      and an increase in bias.\n",
      " |      Values must be in the range `(0.0, 1.0]`.\n",
      " |  \n",
      " |  criterion : {'friedman_mse', 'squared_error'}, default='friedman_mse'\n",
      " |      The function to measure the quality of a split. Supported criteria are\n",
      " |      \"friedman_mse\" for the mean squared error with improvement score by\n",
      " |      Friedman, \"squared_error\" for mean squared error. The default value of\n",
      " |      \"friedman_mse\" is generally the best as it can provide a better\n",
      " |      approximation in some cases.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, values must be in the range `[2, inf)`.\n",
      " |      - If float, values must be in the range `(0.0, 1.0]` and `min_samples_split`\n",
      " |        will be `ceil(min_samples_split * n_samples)`.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, values must be in the range `[1, inf)`.\n",
      " |      - If float, values must be in the range `(0.0, 1.0)` and `min_samples_leaf`\n",
      " |        will be `ceil(min_samples_leaf * n_samples)`.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |      Values must be in the range `[0.0, 0.5]`.\n",
      " |  \n",
      " |  max_depth : int or None, default=3\n",
      " |      Maximum depth of the individual regression estimators. The maximum\n",
      " |      depth limits the number of nodes in the tree. Tune this parameter\n",
      " |      for best performance; the best value depends on the interaction\n",
      " |      of the input variables. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |      If int, values must be in the range `[1, inf)`.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |      Values must be in the range `[0.0, inf)`.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  init : estimator or 'zero', default=None\n",
      " |      An estimator object that is used to compute the initial predictions.\n",
      " |      ``init`` has to provide :term:`fit` and :term:`predict`. If 'zero', the\n",
      " |      initial raw predictions are set to zero. By default a\n",
      " |      ``DummyEstimator`` is used, predicting either the average target value\n",
      " |      (for loss='squared_error'), or a quantile for the other losses.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls the random seed given to each Tree estimator at each\n",
      " |      boosting iteration.\n",
      " |      In addition, it controls the random permutation of the features at\n",
      " |      each split (see Notes for more details).\n",
      " |      It also controls the random splitting of the training data to obtain a\n",
      " |      validation set if `n_iter_no_change` is not None.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  max_features : {'sqrt', 'log2'}, int or float, default=None\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, values must be in the range `[1, inf)`.\n",
      " |      - If float, values must be in the range `(0.0, 1.0]` and the features\n",
      " |        considered at each split will be `max(1, int(max_features * n_features_in_))`.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Choosing `max_features < n_features` leads to a reduction of variance\n",
      " |      and an increase in bias.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  alpha : float, default=0.9\n",
      " |      The alpha-quantile of the huber loss function and the quantile\n",
      " |      loss function. Only if ``loss='huber'`` or ``loss='quantile'``.\n",
      " |      Values must be in the range `(0.0, 1.0)`.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Enable verbose output. If 1 then it prints progress and performance\n",
      " |      once in a while (the more trees the lower the frequency). If greater\n",
      " |      than 1 then it prints progress and performance for every tree.\n",
      " |      Values must be in the range `[0, inf)`.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      Values must be in the range `[2, inf)`.\n",
      " |      If None, then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just erase the\n",
      " |      previous solution. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  validation_fraction : float, default=0.1\n",
      " |      The proportion of training data to set aside as validation set for\n",
      " |      early stopping. Values must be in the range `(0.0, 1.0)`.\n",
      " |      Only used if ``n_iter_no_change`` is set to an integer.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  n_iter_no_change : int, default=None\n",
      " |      ``n_iter_no_change`` is used to decide if early stopping will be used\n",
      " |      to terminate training when validation score is not improving. By\n",
      " |      default it is set to None to disable early stopping. If set to a\n",
      " |      number, it will set aside ``validation_fraction`` size of the training\n",
      " |      data as validation and terminate training when validation score is not\n",
      " |      improving in all of the previous ``n_iter_no_change`` numbers of\n",
      " |      iterations.\n",
      " |      Values must be in the range `[1, inf)`.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      Tolerance for the early stopping. When the loss is not improving\n",
      " |      by at least tol for ``n_iter_no_change`` iterations (if set to a\n",
      " |      number), the training stops.\n",
      " |      Values must be in the range `[0.0, inf)`.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed.\n",
      " |      Values must be in the range `[0.0, inf)`.\n",
      " |      See :ref:`minimal_cost_complexity_pruning` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The impurity-based feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |  \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |  \n",
      " |  oob_improvement_ : ndarray of shape (n_estimators,)\n",
      " |      The improvement in loss on the out-of-bag samples\n",
      " |      relative to the previous iteration.\n",
      " |      ``oob_improvement_[0]`` is the improvement in\n",
      " |      loss of the first stage over the ``init`` estimator.\n",
      " |      Only available if ``subsample < 1.0``.\n",
      " |  \n",
      " |  oob_scores_ : ndarray of shape (n_estimators,)\n",
      " |      The full history of the loss values on the out-of-bag\n",
      " |      samples. Only available if `subsample < 1.0`.\n",
      " |  \n",
      " |      .. versionadded:: 1.3\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      The last value of the loss on the out-of-bag samples. It is\n",
      " |      the same as `oob_scores_[-1]`. Only available if `subsample < 1.0`.\n",
      " |  \n",
      " |      .. versionadded:: 1.3\n",
      " |  \n",
      " |  train_score_ : ndarray of shape (n_estimators,)\n",
      " |      The i-th score ``train_score_[i]`` is the loss of the\n",
      " |      model at iteration ``i`` on the in-bag sample.\n",
      " |      If ``subsample == 1`` this is the loss on the training data.\n",
      " |  \n",
      " |  init_ : estimator\n",
      " |      The estimator that provides the initial predictions.\n",
      " |      Set via the ``init`` argument or ``loss.init_estimator``.\n",
      " |  \n",
      " |  estimators_ : ndarray of DecisionTreeRegressor of shape (n_estimators, 1)\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  n_estimators_ : int\n",
      " |      The number of estimators as selected by early stopping (if\n",
      " |      ``n_iter_no_change`` is specified). Otherwise it is set to\n",
      " |      ``n_estimators``.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  max_features_ : int\n",
      " |      The inferred value of max_features.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  HistGradientBoostingRegressor : Histogram-based Gradient Boosting\n",
      " |      Classification Tree.\n",
      " |  sklearn.tree.DecisionTreeRegressor : A decision tree regressor.\n",
      " |  sklearn.ensemble.RandomForestRegressor : A random forest regressor.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data and\n",
      " |  ``max_features=n_features``, if the improvement of the criterion is\n",
      " |  identical for several splits enumerated during the search of the best\n",
      " |  split. To obtain a deterministic behaviour during fitting,\n",
      " |  ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  J. Friedman, Greedy Function Approximation: A Gradient Boosting\n",
      " |  Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.\n",
      " |  \n",
      " |  J. Friedman, Stochastic Gradient Boosting, 1999\n",
      " |  \n",
      " |  T. Hastie, R. Tibshirani and J. Friedman.\n",
      " |  Elements of Statistical Learning Ed. 2, Springer, 2009.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import make_regression\n",
      " |  >>> from sklearn.ensemble import GradientBoostingRegressor\n",
      " |  >>> from sklearn.model_selection import train_test_split\n",
      " |  >>> X, y = make_regression(random_state=0)\n",
      " |  >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      " |  ...     X, y, random_state=0)\n",
      " |  >>> reg = GradientBoostingRegressor(random_state=0)\n",
      " |  >>> reg.fit(X_train, y_train)\n",
      " |  GradientBoostingRegressor(random_state=0)\n",
      " |  >>> reg.predict(X_test[1:2])\n",
      " |  array([-61...])\n",
      " |  >>> reg.score(X_test, y_test)\n",
      " |  0.4...\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GradientBoostingRegressor\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      BaseGradientBoosting\n",
      " |      sklearn.ensemble._base.BaseEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, loss='squared_error', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, init=None, random_state=None, max_features=None, alpha=0.9, verbose=0, max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the ensemble to X, return leaf indices.\n",
      " |      \n",
      " |      .. versionadded:: 0.17\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will\n",
      " |          be converted to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array-like of shape (n_samples, n_estimators)\n",
      " |          For each datapoint x in X and for each tree in the ensemble,\n",
      " |          return the index of the leaf x ends up in each estimator.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict regression target for X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,)\n",
      " |          The predicted values.\n",
      " |  \n",
      " |  set_fit_request(self: sklearn.ensemble._gb.GradientBoostingRegressor, *, monitor: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.ensemble._gb.GradientBoostingRegressor\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      monitor : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``monitor`` parameter in ``fit``.\n",
      " |      \n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_score_request(self: sklearn.ensemble._gb.GradientBoostingRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.ensemble._gb.GradientBoostingRegressor\n",
      " |      Request metadata passed to the ``score`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  staged_predict(self, X)\n",
      " |      Predict regression target at each stage for X.\n",
      " |      \n",
      " |      This method allows monitoring (i.e. determine error on testing set)\n",
      " |      after each stage.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      y : generator of ndarray of shape (n_samples,)\n",
      " |          The predicted value of the input samples.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination of the prediction.\n",
      " |      \n",
      " |      The coefficient of determination :math:`R^2` is defined as\n",
      " |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      " |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      " |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always predicts\n",
      " |      the expected value of `y`, disregarding the input features, would get\n",
      " |      a :math:`R^2` score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseGradientBoosting:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, monitor=None)\n",
      " |      Fit the gradient boosting model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values (strings or integers in classification, real numbers\n",
      " |          in regression)\n",
      " |          For classification, labels must correspond to classes.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      monitor : callable, default=None\n",
      " |          The monitor is called after each iteration with the current\n",
      " |          iteration, a reference to the estimator and the local variables of\n",
      " |          ``_fit_stages`` as keyword arguments ``callable(i, self,\n",
      " |          locals())``. If the callable returns ``True`` the fitting procedure\n",
      " |          is stopped. The monitor can be used for various things such as\n",
      " |          computing held-out estimates, early stopping, model introspect, and\n",
      " |          snapshoting.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseGradientBoosting:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      The impurity-based feature importances.\n",
      " |      \n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |      \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          The values of this array sum to 1, unless all trees are single node\n",
      " |          trees consisting of only the root node, in which case it will be an\n",
      " |          array of zeros.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Return the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  base_estimator_\n",
      " |      Estimator used to grow the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print some info about it and it's hyperparameters\n",
    "print(help(GradientBoostingRegressor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a908553-159e-4d07-a87f-0f51eeeae9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "gb = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "022ea4df-e761-47fd-8db7-550acc3cf327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data. Took only took a few min to run on my laptop\n",
    "gb.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "05e1eb81-4a21-4e28-9aa0-3e9e52cf241e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45685882 0.41726136 0.48079732 ... 0.22242709 0.38249673 0.71868298]\n"
     ]
    }
   ],
   "source": [
    "# Run model on test data to get the predicted danceability scores\n",
    "y_pred = gb.predict(x_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "756fa9ec-b641-4cf5-809e-db6095075995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07277560281870248\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean absolute error between predicted danceability and actual danceability in the test data\n",
    "mean_absolute_error(y_test, y_pred)\n",
    "print(mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "84bcf1cb-90f3-4895-876f-f2a96e5edd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is pretty good accuracy. The model's predictions of danceability were only an avg of 0.0728 pts away from the actual\n",
    "# danceability which is slightly better than the best random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "8d0e87e2-e740-4fc3-bc0b-10fc96bcd44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try some hyperparameter tuning\n",
    "# n_estimators is the number of stages or trees. default is 100\n",
    "# max_depth is number of nodes in a tree. Default is 3\n",
    "parameters = {\n",
    "\t'n_estimators': [50, 100, 250, 500],\n",
    "\t'max_depth': [3, 7, 9, None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "e34682c3-1c89-4615-ad34-153e4a31b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up cross validation with the hyperparameter tuning. Will create 4x4=16 models using all possible\n",
    "# combos of the hyperparameters, and use 4/5 of training data for train and the other 1/5 to test\n",
    "cv = GridSearchCV(gb, parameters, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "7eed5c2d-7bf0-4caf-a5cb-98e32982d11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [3, 7, 9, None],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 250, 500]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [3, 7, 9, None],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 250, 500]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={'max_depth': [3, 7, 9, None],\n",
       "                         'n_estimators': [50, 100, 250, 500]})"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "# This took overnight on my laptop.  Kernel went idle after 3 hours, but the notebook cell didn't finish executing \n",
    "# till the next morning. Should time it if I ever run it again\n",
    "cv.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "59b7e126-a9af-49e8-a1a3-3b688e81e368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'max_depth': 3, 'n_estimators': 500}\n",
      "\n",
      "0.747 (+/-0.018) for {'max_depth': 3, 'n_estimators': 50}\n",
      "0.774 (+/-0.017) for {'max_depth': 3, 'n_estimators': 100}\n",
      "0.793 (+/-0.014) for {'max_depth': 3, 'n_estimators': 250}\n",
      "0.8 (+/-0.013) for {'max_depth': 3, 'n_estimators': 500}\n",
      "0.776 (+/-0.01) for {'max_depth': 7, 'n_estimators': 50}\n",
      "0.784 (+/-0.009) for {'max_depth': 7, 'n_estimators': 100}\n",
      "0.786 (+/-0.01) for {'max_depth': 7, 'n_estimators': 250}\n",
      "0.787 (+/-0.009) for {'max_depth': 7, 'n_estimators': 500}\n",
      "0.764 (+/-0.014) for {'max_depth': 9, 'n_estimators': 50}\n",
      "0.769 (+/-0.012) for {'max_depth': 9, 'n_estimators': 100}\n",
      "0.77 (+/-0.013) for {'max_depth': 9, 'n_estimators': 250}\n",
      "0.77 (+/-0.013) for {'max_depth': 9, 'n_estimators': 500}\n",
      "0.498 (+/-0.028) for {'max_depth': None, 'n_estimators': 50}\n",
      "0.495 (+/-0.031) for {'max_depth': None, 'n_estimators': 100}\n",
      "0.495 (+/-0.026) for {'max_depth': None, 'n_estimators': 250}\n",
      "0.494 (+/-0.029) for {'max_depth': None, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "f7d41f61-47b2-481f-9d5a-89a29be7fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model is: {'max_depth': 3, 'n_estimators': 500} with accuracy of about 80%\n",
    "# Second best model is: {'max_depth': 3, 'n_estimators': 250} with accuracy of about 79%\n",
    "# Third best model is: {'max_depth': 7, 'n_estimators': 500} with accuracy of about 79%\n",
    "\n",
    "# of the models with 100 trees or less, the best is:\n",
    "# {'max_depth': 7, 'n_estimators': 100} with 78% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8aca653-96da-440f-8949-3bab62ab9834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the 2 best sets of hyperparameters, and the third smaller model with good accuracy but fewer trees\n",
    "# Fewer trees will mean faster to run, since these trees build upon each other and therefore are built sequentially\n",
    "gb1 = GradientBoostingRegressor(max_depth=3, n_estimators=500)\n",
    "gb2 = GradientBoostingRegressor(max_depth=3, n_estimators=250)\n",
    "gb3 = GradientBoostingRegressor(max_depth=7, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09a95f26-3d43-466f-9eb7-0475f059945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models on training data.  Time the one with 500 trees.\n",
    "start = time.time()\n",
    "gb1.fit(x_train, y_train.values.ravel())\n",
    "end = time.time()\n",
    "model_name_fit_or_predict_time = (end - start) # will return number of seconds it takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "1085499d-97f9-467b-8d1a-b1b69c626620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model took about  4.33 minutes to run\n"
     ]
    }
   ],
   "source": [
    "print('This model took about ', round(model_name_fit_or_predict_time / 60, 2), 'minutes to run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "7762c2de-4a1d-4ed1-9db5-2e3c72270eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(n_estimators=250)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" checked><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(n_estimators=250)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(n_estimators=250)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model on training data\n",
    "gb2.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c4a01683-6a2c-4ae1-a8d3-d94e3d59488e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(max_depth=7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" checked><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(max_depth=7)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(max_depth=7)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model on training data\n",
    "gb3.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "6257f1c2-3d59-4338-94f4-961bf4f5398b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06661576492829122\n",
      "0.0686302551720496\n",
      "0.06888456269205578\n"
     ]
    }
   ],
   "source": [
    "# Check how good these models are on the training data. It's possible the best model was overfitting\n",
    "# and might not work as well on the training data\n",
    "for mdl in [gb1, gb2, gb3]:\n",
    "    y_pred = mdl.predict(x_test) # get the predicted y-values\n",
    "    print(mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26171f96-5529-4028-bd31-d43915b5bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are great models!  The best, with 500 trees, predicts danceability and is only off the actual score by 0.0666 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "453ea5ab-bc05-4ae1-b0fc-6cb03993ee64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./GradientBoosterRegressor_model.pkl']"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pickle best model\n",
    "joblib.dump(gb1, './GradientBoosterRegressor_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a57b9d-4741-426f-b902-1e24fde2340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion\n",
    "# I wanted to use my best model to predict the danceability of some brand new popular songs using their temporal\n",
    "# features, but alas, spotify no longer provides this data on songs. So, instead, lets simulate using this model\n",
    "# by selecting a couple of songs from the training data that we know are high, low, and medium in danceability\n",
    "# and see what the model says about them\n",
    "\n",
    "# I happen to know that song #8230 Wooden Ships is not very danceable with a score of 0.05166771\n",
    "# while song #11564 Shakkei (Remixed) by Origamibiro is medium danceable with a score of 0.44688061\n",
    "# and song #9437 Niris by Nicky Cook is supposed to be super danceable with a score of 0.94879937\n",
    "# But lets see what the model says"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b5d3fbb-e705-4447-a761-9f8934f06408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  instrumentalness    tempo  temporal_features0  \\\n",
      "246         8230          0.750180  234.501            0.208941   \n",
      "2135       11564          0.779940   93.495            0.265258   \n",
      "2533        9437          0.519803  124.035            0.431988   \n",
      "\n",
      "      temporal_features1  temporal_features2  temporal_features3  \\\n",
      "246             0.199116            0.165297            0.119200   \n",
      "2135            0.622987            0.496264            0.125611   \n",
      "2533            0.444268            0.396486            0.235402   \n",
      "\n",
      "      temporal_features4  temporal_features5  temporal_features6  ...  \\\n",
      "246             0.228610            0.145534            0.215040  ...   \n",
      "2135            0.320337            0.070170            0.228531  ...   \n",
      "2533            0.294019            0.271680            0.205089  ...   \n",
      "\n",
      "      temporal_features214  temporal_features215  temporal_features216  \\\n",
      "246              -3.221379              9.918351              0.685443   \n",
      "2135             -0.242559             -0.207658              0.314515   \n",
      "2533             -1.116827              2.337863              0.312406   \n",
      "\n",
      "      temporal_features217  temporal_features218  temporal_features219  \\\n",
      "246                0.43043              0.512893               0.06227   \n",
      "2135               0.28934              0.046540               0.06023   \n",
      "2533               0.25916              0.018925               0.06444   \n",
      "\n",
      "      temporal_features220  temporal_features221  temporal_features222  \\\n",
      "246                6.16508               6.10281              3.432451   \n",
      "2135               3.76739               3.70716              4.999788   \n",
      "2533               1.52222               1.45778              1.978682   \n",
      "\n",
      "      temporal_features223  \n",
      "246              16.253798  \n",
      "2135             63.627140  \n",
      "2533             12.733705  \n",
      "\n",
      "[3 rows x 227 columns]\n"
     ]
    }
   ],
   "source": [
    "# read it in again with the id's\n",
    "x_test = pd.read_csv(\"./x_test.csv\")\n",
    "x_test_3_songs = x_test[x_test['Unnamed: 0'].isin([8230, 11564, 9437])]\n",
    "print(x_test_3_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6086a4cf-94fa-41d8-8e81-7daefd56fd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ct/78f3t3tx0wd8rkf818c7rxd00000gp/T/ipykernel_23743/3679984822.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_test_3_songs.drop('Unnamed: 0', axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "x_test_3_songs.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05feb671-1087-4b3b-984e-2f28237ff3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>temporal_features0</th>\n",
       "      <th>temporal_features1</th>\n",
       "      <th>temporal_features2</th>\n",
       "      <th>temporal_features3</th>\n",
       "      <th>temporal_features4</th>\n",
       "      <th>temporal_features5</th>\n",
       "      <th>temporal_features6</th>\n",
       "      <th>temporal_features7</th>\n",
       "      <th>...</th>\n",
       "      <th>temporal_features214</th>\n",
       "      <th>temporal_features215</th>\n",
       "      <th>temporal_features216</th>\n",
       "      <th>temporal_features217</th>\n",
       "      <th>temporal_features218</th>\n",
       "      <th>temporal_features219</th>\n",
       "      <th>temporal_features220</th>\n",
       "      <th>temporal_features221</th>\n",
       "      <th>temporal_features222</th>\n",
       "      <th>temporal_features223</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.750180</td>\n",
       "      <td>234.501</td>\n",
       "      <td>0.208941</td>\n",
       "      <td>0.199116</td>\n",
       "      <td>0.165297</td>\n",
       "      <td>0.119200</td>\n",
       "      <td>0.228610</td>\n",
       "      <td>0.145534</td>\n",
       "      <td>0.215040</td>\n",
       "      <td>0.307783</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.221379</td>\n",
       "      <td>9.918351</td>\n",
       "      <td>0.685443</td>\n",
       "      <td>0.43043</td>\n",
       "      <td>0.512893</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>6.16508</td>\n",
       "      <td>6.10281</td>\n",
       "      <td>3.432451</td>\n",
       "      <td>16.253798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>0.779940</td>\n",
       "      <td>93.495</td>\n",
       "      <td>0.265258</td>\n",
       "      <td>0.622987</td>\n",
       "      <td>0.496264</td>\n",
       "      <td>0.125611</td>\n",
       "      <td>0.320337</td>\n",
       "      <td>0.070170</td>\n",
       "      <td>0.228531</td>\n",
       "      <td>0.134348</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.242559</td>\n",
       "      <td>-0.207658</td>\n",
       "      <td>0.314515</td>\n",
       "      <td>0.28934</td>\n",
       "      <td>0.046540</td>\n",
       "      <td>0.06023</td>\n",
       "      <td>3.76739</td>\n",
       "      <td>3.70716</td>\n",
       "      <td>4.999788</td>\n",
       "      <td>63.627140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2533</th>\n",
       "      <td>0.519803</td>\n",
       "      <td>124.035</td>\n",
       "      <td>0.431988</td>\n",
       "      <td>0.444268</td>\n",
       "      <td>0.396486</td>\n",
       "      <td>0.235402</td>\n",
       "      <td>0.294019</td>\n",
       "      <td>0.271680</td>\n",
       "      <td>0.205089</td>\n",
       "      <td>0.219194</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.116827</td>\n",
       "      <td>2.337863</td>\n",
       "      <td>0.312406</td>\n",
       "      <td>0.25916</td>\n",
       "      <td>0.018925</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>1.52222</td>\n",
       "      <td>1.45778</td>\n",
       "      <td>1.978682</td>\n",
       "      <td>12.733705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      instrumentalness    tempo  temporal_features0  temporal_features1  \\\n",
       "246           0.750180  234.501            0.208941            0.199116   \n",
       "2135          0.779940   93.495            0.265258            0.622987   \n",
       "2533          0.519803  124.035            0.431988            0.444268   \n",
       "\n",
       "      temporal_features2  temporal_features3  temporal_features4  \\\n",
       "246             0.165297            0.119200            0.228610   \n",
       "2135            0.496264            0.125611            0.320337   \n",
       "2533            0.396486            0.235402            0.294019   \n",
       "\n",
       "      temporal_features5  temporal_features6  temporal_features7  ...  \\\n",
       "246             0.145534            0.215040            0.307783  ...   \n",
       "2135            0.070170            0.228531            0.134348  ...   \n",
       "2533            0.271680            0.205089            0.219194  ...   \n",
       "\n",
       "      temporal_features214  temporal_features215  temporal_features216  \\\n",
       "246              -3.221379              9.918351              0.685443   \n",
       "2135             -0.242559             -0.207658              0.314515   \n",
       "2533             -1.116827              2.337863              0.312406   \n",
       "\n",
       "      temporal_features217  temporal_features218  temporal_features219  \\\n",
       "246                0.43043              0.512893               0.06227   \n",
       "2135               0.28934              0.046540               0.06023   \n",
       "2533               0.25916              0.018925               0.06444   \n",
       "\n",
       "      temporal_features220  temporal_features221  temporal_features222  \\\n",
       "246                6.16508               6.10281              3.432451   \n",
       "2135               3.76739               3.70716              4.999788   \n",
       "2533               1.52222               1.45778              1.978682   \n",
       "\n",
       "      temporal_features223  \n",
       "246              16.253798  \n",
       "2135             63.627140  \n",
       "2533             12.733705  \n",
       "\n",
       "[3 rows x 226 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_3_songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa8f3f68-465e-4673-b676-78e1b199f5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04867972 0.51086412 0.83163573]\n"
     ]
    }
   ],
   "source": [
    "y_pred = gb1.predict(x_test_3_songs) # get the predicted y-values\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f185bfd-4b59-4c97-9b35-d9f8457609fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These danceability scores are pretty close!\n",
    "# Model agreed that Wooden Ships is not very danceable with a score of 0.04867972 (actual: 0.05166771)\n",
    "# Model agreed that Shakkei (Remixed) by Origamibiro is medium danceable with a score of 0.51086412 (actual 0.44688061)\n",
    "# And Model agreed that Niris by Nicky Cook is super danceable with a score of 0.83163573 (actual 0.94879937)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233e234d-5fbd-471e-adfe-46adfdde71b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
